1    6742
7    6265
3    6131
2    5958
9    5949
0    5923
8    5851
4    5842
5    5421
6     592
dtype: int64
Epoch 1/100
86/86 - 19s - loss: 2.9937 - accuracy: 0.2516 - val_loss: 1.7561 - val_accuracy: 0.3730 - 19s/epoch - 224ms/step
Epoch 2/100
86/86 - 19s - loss: 1.4659 - accuracy: 0.4825 - val_loss: 1.0612 - val_accuracy: 0.6970 - 19s/epoch - 217ms/step
Epoch 3/100
86/86 - 17s - loss: 0.8560 - accuracy: 0.7756 - val_loss: 0.7498 - val_accuracy: 0.8461 - 17s/epoch - 201ms/step
Epoch 4/100
86/86 - 18s - loss: 0.6350 - accuracy: 0.8642 - val_loss: 0.6017 - val_accuracy: 0.8831 - 18s/epoch - 213ms/step
Epoch 5/100
86/86 - 17s - loss: 0.5380 - accuracy: 0.8916 - val_loss: 0.5393 - val_accuracy: 0.8888 - 17s/epoch - 201ms/step
Epoch 6/100
86/86 - 17s - loss: 0.4769 - accuracy: 0.8992 - val_loss: 0.4860 - val_accuracy: 0.8958 - 17s/epoch - 201ms/step
Epoch 7/100
86/86 - 18s - loss: 0.4419 - accuracy: 0.8893 - val_loss: 0.4514 - val_accuracy: 0.8589 - 18s/epoch - 210ms/step
Epoch 8/100
86/86 - 17s - loss: 0.3377 - accuracy: 0.9034 - val_loss: 0.3570 - val_accuracy: 0.9087 - 17s/epoch - 202ms/step
Epoch 9/100
86/86 - 18s - loss: 0.2614 - accuracy: 0.9269 - val_loss: 0.2828 - val_accuracy: 0.9250 - 18s/epoch - 212ms/step
Epoch 10/100
86/86 - 18s - loss: 0.2317 - accuracy: 0.9331 - val_loss: 0.3021 - val_accuracy: 0.9210 - 18s/epoch - 204ms/step
Epoch 11/100
86/86 - 18s - loss: 0.2127 - accuracy: 0.9383 - val_loss: 0.2469 - val_accuracy: 0.9340 - 18s/epoch - 210ms/step
Epoch 12/100
86/86 - 18s - loss: 0.1985 - accuracy: 0.9418 - val_loss: 0.2791 - val_accuracy: 0.9245 - 18s/epoch - 204ms/step
Epoch 13/100
86/86 - 18s - loss: 0.1879 - accuracy: 0.9440 - val_loss: 0.2382 - val_accuracy: 0.9358 - 18s/epoch - 209ms/step
Epoch 14/100
86/86 - 18s - loss: 0.1712 - accuracy: 0.9478 - val_loss: 0.2185 - val_accuracy: 0.9431 - 18s/epoch - 210ms/step
Epoch 15/100
86/86 - 18s - loss: 0.1569 - accuracy: 0.9514 - val_loss: 0.2288 - val_accuracy: 0.9368 - 18s/epoch - 207ms/step
Epoch 16/100
86/86 - 18s - loss: 0.1518 - accuracy: 0.9529 - val_loss: 0.2171 - val_accuracy: 0.9412 - 18s/epoch - 210ms/step
Epoch 17/100
86/86 - 18s - loss: 0.1409 - accuracy: 0.9552 - val_loss: 0.2130 - val_accuracy: 0.9447 - 18s/epoch - 205ms/step
Epoch 18/100
86/86 - 18s - loss: 0.1363 - accuracy: 0.9576 - val_loss: 0.2090 - val_accuracy: 0.9448 - 18s/epoch - 207ms/step
Epoch 19/100
86/86 - 18s - loss: 0.1285 - accuracy: 0.9593 - val_loss: 0.2174 - val_accuracy: 0.9449 - 18s/epoch - 211ms/step


Control Results:
[[ 943    0   13    3    0    9    0    0   12    0]
 [   0 1115    2    0    0    5    0   12    0    1]
 [  27    0  964    0    0   12    0   15    7    7]
 [   6    0    2  973    0   25    0    0    4    0]
 [   0    0    0    0  948    0    0    5    1   28]
 [   6    6    7   16    0  854    0    2    1    0]
 [  76    2   22   63  179    8   26   14  557   11]
 [   0   17   22    1    3    2    0  976    0    7]
 [  26    0    8    4    6    0    0    0  920   10]
 [   5    0   41    0    7    1    0   20   11  924]]
              precision    recall  f1-score   support

           0       0.87      0.96      0.91       980
           1       0.98      0.98      0.98      1135
           2       0.89      0.93      0.91      1032
           3       0.92      0.96      0.94      1010
           4       0.83      0.97      0.89       982
           5       0.93      0.96      0.94       892
           6       1.00      0.03      0.05       958
           7       0.93      0.95      0.94      1028
           8       0.61      0.94      0.74       974
           9       0.94      0.92      0.93      1009

    accuracy                           0.86     10000
   macro avg       0.89      0.86      0.82     10000
weighted avg       0.89      0.86      0.83     10000



32/32 - 3s - loss: 1.2210 - accuracy: 0.6120 - 3s/epoch - 108ms/step
Epoch 1/100
86/86 - 34s - loss: 1.4475 - accuracy: 0.5610 - val_loss: 0.6566 - val_accuracy: 0.7717 - 34s/epoch - 391ms/step
Epoch 2/100
86/86 - 32s - loss: 0.5345 - accuracy: 0.8010 - val_loss: 0.4613 - val_accuracy: 0.8187 - 32s/epoch - 373ms/step
Epoch 3/100
86/86 - 32s - loss: 0.4213 - accuracy: 0.8258 - val_loss: 0.4038 - val_accuracy: 0.8323 - 32s/epoch - 368ms/step
Epoch 4/100
86/86 - 32s - loss: 0.3728 - accuracy: 0.8362 - val_loss: 0.3668 - val_accuracy: 0.8379 - 32s/epoch - 366ms/step
Epoch 5/100
86/86 - 31s - loss: 0.3397 - accuracy: 0.8444 - val_loss: 0.3381 - val_accuracy: 0.8436 - 31s/epoch - 363ms/step
Epoch 6/100
86/86 - 31s - loss: 0.3156 - accuracy: 0.8490 - val_loss: 0.3189 - val_accuracy: 0.8484 - 31s/epoch - 365ms/step
Epoch 7/100
86/86 - 31s - loss: 0.2999 - accuracy: 0.8525 - val_loss: 0.3080 - val_accuracy: 0.8501 - 31s/epoch - 364ms/step
Epoch 8/100
86/86 - 32s - loss: 0.2879 - accuracy: 0.8547 - val_loss: 0.2982 - val_accuracy: 0.8524 - 32s/epoch - 368ms/step
Epoch 9/100
86/86 - 32s - loss: 0.2747 - accuracy: 0.8572 - val_loss: 0.2903 - val_accuracy: 0.8546 - 32s/epoch - 373ms/step
Epoch 10/100
86/86 - 32s - loss: 0.2693 - accuracy: 0.8580 - val_loss: 0.2791 - val_accuracy: 0.8569 - 32s/epoch - 371ms/step
Epoch 11/100
86/86 - 31s - loss: 0.2604 - accuracy: 0.8604 - val_loss: 0.2736 - val_accuracy: 0.8593 - 31s/epoch - 365ms/step
Epoch 12/100
86/86 - 22s - loss: 0.2535 - accuracy: 0.8615 - val_loss: 0.2692 - val_accuracy: 0.8582 - 22s/epoch - 255ms/step
Epoch 13/100
86/86 - 17s - loss: 0.2478 - accuracy: 0.8628 - val_loss: 0.2671 - val_accuracy: 0.8589 - 17s/epoch - 197ms/step
Epoch 14/100
86/86 - 25s - loss: 0.2443 - accuracy: 0.8634 - val_loss: 0.2630 - val_accuracy: 0.8604 - 25s/epoch - 290ms/step
Epoch 15/100
86/86 - 30s - loss: 0.2399 - accuracy: 0.8645 - val_loss: 0.2629 - val_accuracy: 0.8599 - 30s/epoch - 354ms/step


One Shot Results:
[[ 974    0    0    0    0    0    0    2    4    0]
 [   1 1121    4    0    0    0    0    0    9    0]
 [   4    3  997    3    3    0    0   13    9    0]
 [   2    2    5  985    0    6    0    7    3    0]
 [   4    1    4    0  969    0    0    4    0    0]
 [   9    1    0    5    0  871    0    3    3    0]
 [ 784   14   18    1   47   56    0    2   36    0]
 [   5    2    9    3    0    0    0 1007    2    0]
 [  12    1    8    5    4    3    0    7  934    0]
 [ 922   10    4    7   19    6    0   28   13    0]]
              precision    recall  f1-score   support

           0       0.36      0.99      0.53       980
           1       0.97      0.99      0.98      1135
           2       0.95      0.97      0.96      1032
           3       0.98      0.98      0.98      1010
           4       0.93      0.99      0.96       982
           5       0.92      0.98      0.95       892
           6       0.00      0.00      0.00       958
           7       0.94      0.98      0.96      1028
           8       0.92      0.96      0.94       974
           9       0.00      0.00      0.00      1009

    accuracy                           0.79     10000
   macro avg       0.70      0.78      0.72     10000
weighted avg       0.70      0.79      0.73     10000



32/32 - 3s - loss: 1.3005 - accuracy: 0.5770 - 3s/epoch - 83ms/step
Epoch 1/100
Performance measure set to val_accuracy
Model performance reached 0.96, sparsifying to 55
86/86 - 33s - loss: 0.2919 - accuracy: 0.9147 - val_loss: 0.1320 - val_accuracy: 0.9610 - 33s/epoch - 385ms/step
Epoch 2/100
Model performance reached 0.97, sparsifying to 60
86/86 - 31s - loss: 0.1011 - accuracy: 0.9701 - val_loss: 0.0899 - val_accuracy: 0.9730 - 31s/epoch - 357ms/step
Epoch 3/100
Model performance reached 0.98, sparsifying to 65
86/86 - 32s - loss: 0.0672 - accuracy: 0.9798 - val_loss: 0.0693 - val_accuracy: 0.9799 - 32s/epoch - 369ms/step
Epoch 4/100
Model performance reached 0.98, sparsifying to 70
86/86 - 31s - loss: 0.0667 - accuracy: 0.9793 - val_loss: 0.0624 - val_accuracy: 0.9815 - 31s/epoch - 361ms/step
Epoch 5/100
Model performance reached 0.98, sparsifying to 75
86/86 - 26s - loss: 0.0972 - accuracy: 0.9723 - val_loss: 0.0607 - val_accuracy: 0.9823 - 26s/epoch - 300ms/step
Epoch 6/100
Model performance reached 0.98, sparsifying to 80
86/86 - 31s - loss: 0.1193 - accuracy: 0.9657 - val_loss: 0.0625 - val_accuracy: 0.9819 - 31s/epoch - 356ms/step
Epoch 7/100
Model performance reached 0.98, sparsifying to 85
86/86 - 31s - loss: 0.0740 - accuracy: 0.9773 - val_loss: 0.0643 - val_accuracy: 0.9817 - 31s/epoch - 364ms/step
Epoch 8/100
Model performance reached 0.98, sparsifying to 90
86/86 - 32s - loss: 0.0975 - accuracy: 0.9702 - val_loss: 0.0690 - val_accuracy: 0.9791 - 32s/epoch - 372ms/step
Epoch 9/100
Model performance reached 0.97, sparsifying to 95
86/86 - 32s - loss: 0.1905 - accuracy: 0.9437 - val_loss: 0.0959 - val_accuracy: 0.9721 - 32s/epoch - 373ms/step
Epoch 10/100
Model performance has not reached pruning threshold for 1 epoch(s)
86/86 - 31s - loss: 1.1511 - accuracy: 0.4719 - val_loss: 0.7524 - val_accuracy: 0.5344 - 31s/epoch - 363ms/step
Epoch 11/100
Model performance has not reached pruning threshold for 2 epoch(s)
86/86 - 31s - loss: 0.7070 - accuracy: 0.5401 - val_loss: 0.6795 - val_accuracy: 0.5484 - 31s/epoch - 363ms/step
Epoch 12/100
Model performance has not reached pruning threshold for 3 epoch(s)
86/86 - 31s - loss: 0.6587 - accuracy: 0.5501 - val_loss: 0.6477 - val_accuracy: 0.5551 - 31s/epoch - 363ms/step
Epoch 13/100
Model performance has not reached pruning threshold for 4 epoch(s)
86/86 - 31s - loss: 0.6318 - accuracy: 0.5544 - val_loss: 0.6260 - val_accuracy: 0.5574 - 31s/epoch - 366ms/step
Epoch 14/100
Model performance has not reached pruning threshold for 5 epoch(s)
Model performance has not reached pruning threshold for 5 epochs, reverting to 90 sparsification and beginning early stopping
86/86 - 30s - loss: 0.6130 - accuracy: 0.5570 - val_loss: 0.6133 - val_accuracy: 0.5607 - 30s/epoch - 353ms/step
Epoch 15/100
Model performance improved to 0.98
86/86 - 31s - loss: 0.0744 - accuracy: 0.9772 - val_loss: 0.0795 - val_accuracy: 0.9771 - 31s/epoch - 363ms/step
Epoch 16/100
Early stopping performance has not met threshold for 1 epochs
86/86 - 32s - loss: 0.0616 - accuracy: 0.9814 - val_loss: 0.0723 - val_accuracy: 0.9791 - 32s/epoch - 377ms/step
Epoch 17/100
Early stopping performance has not met threshold for 2 epochs
86/86 - 31s - loss: 0.0546 - accuracy: 0.9832 - val_loss: 0.0687 - val_accuracy: 0.9806 - 31s/epoch - 366ms/step
Epoch 18/100
Early stopping performance has not met threshold for 3 epochs
86/86 - 25s - loss: 0.0498 - accuracy: 0.9848 - val_loss: 0.0659 - val_accuracy: 0.9813 - 25s/epoch - 296ms/step
Epoch 19/100
Early stopping performance has not met threshold for 4 epochs
86/86 - 30s - loss: 0.0457 - accuracy: 0.9861 - val_loss: 0.0638 - val_accuracy: 0.9810 - 30s/epoch - 352ms/step
Epoch 20/100
Early stopping performance has not met threshold for 5 epochs
Model performance has not met early stopping criteria. Stopping training
86/86 - 30s - loss: 0.0423 - accuracy: 0.9870 - val_loss: 0.0635 - val_accuracy: 0.9819 - 30s/epoch - 351ms/step


Iterative Results:
[[ 974    1    0    0    1    0    1    0    2    1]
 [   0 1127    2    1    0    0    0    1    4    0]
 [   3    2 1004    9    1    0    0    8    5    0]
 [   0    0    3  995    0    3    0    4    5    0]
 [   1    0    0    0  967    0    4    0    1    9]
 [   2    0    1    4    0  877    2    0    6    0]
 [  11    4    2    0   11   14  910    0    6    0]
 [   0    3   11    1    1    1    0 1004    2    5]
 [   7    1   10    4    4   11    4    6  923    4]
 [   1    5    0    6    5    3    0    4   11  974]]
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.98      0.99      0.98      1010
           4       0.98      0.98      0.98       982
           5       0.96      0.98      0.97       892
           6       0.99      0.95      0.97       958
           7       0.98      0.98      0.98      1028
           8       0.96      0.95      0.95       974
           9       0.98      0.97      0.97      1009

    accuracy                           0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000



